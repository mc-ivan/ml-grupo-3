
---

![alt text](recursos/machine-learning.jpg)

# Proyecto de Clasificaci贸n Supervisada - Clasificaci贸n Binaria

## Datos Generales:
**Maestria en Ciencia de Datos e Inteligencia Artifivial V1-E2**

**M贸dulo:** Machine Learning and Deep learning

# GRUPO 3
### Integrantes:
- Karen Torrico 
- Karen Huacota 
- Jessica Luna
- Elvis Miranda
- Ivan Mamani 

**Fecha de Presentaci贸n:** 18/07/2025

---

## 1. Descripci贸n del Problema

En el presente trabajo se aborda un problema de clasificaci贸n supervisada utilizando un conjunto de datos cuyo objetivo es predecir la variable `OBJ`, de naturaleza binaria. Esta variable representa dos posibles categor铆as, configurando un problema de clasificaci贸n binaria.

- **Variable objetivo (target):**  
  `OBJ` (variable binaria). La variable `OBJ` adopta valores 0 o 1, indicando la clase o categor铆a correspondiente a cada observaci贸n.

- **Variables independientes:**  
  El conjunto de datos cuenta con dos grupos diferenciados de variables predictoras:

  **a) Variables Absolutas:**  
  `V1`, `V2`, `V3`, ..., `V30`. Corresponden a valores num茅ricos en escala absoluta, relacionados con caracter铆sticas o mediciones directas de cada observaci贸n.

  **b) Variables Relativas:**  
  `V1_P`, `V2_P`, `V3_P`, ..., `V30_P`. Representan los valores absolutos normalizados respecto al total de las 30 variables originales, expresando proporciones o porcentajes dentro de cada registro.

- **Decisi贸n de trabajo:**  
  Tras un an谩lisis preliminar, se decidi贸 trabajar con las **variables originales en valores absolutos** (`V1` a `V30`) para la construcci贸n de los modelos.  
  La decisi贸n se basa en que las variables relativas (`V1_P` a `V30_P`) reflejan 煤nicamente proporciones internas, que pueden resultar insuficientes para capturar relaciones m谩s complejas o magnitudes reales entre observaciones.  
  Al emplear las variables absolutas se conserva la informaci贸n completa de las mediciones, permitiendo a los modelos explorar tanto la relaci贸n entre valores individuales como su escala.

## 2. An谩lisis Exploratorio del Dataset

El dataset `GRUPO 3_1.zip` utilizado en este laboratorio est谩 compuesto por un total de **10,000 registros (filas)** y **66 columnas** en su versi贸n original.

### 2.1. Estructura inicial del Dataset
- **Cantidad de filas (observaciones):** 10,000  
- **Cantidad de columnas (variables):** 66  

### 2.2. Composici贸n de las columnas
- **1 variable objetivo:** `OBJ` (variable binaria: clasificaci贸n entre dos categor铆as)

- **30 variables independientes en valores absolutos:**  
  - `V1`, `V2`, `V3`, ..., `V30`  

- **30 variables independientes en valores relativos (proporciones):**  
  - `V1_P`, `V2_P`, `V3_P`, ..., `V30_P`  

- **5 columnas t茅cnicas o auxiliares inicialmente presentes:**  
  - `ALEAT`, `ID`, `VT`, `V31_P`, `V31_P.1`  
  - Estas columnas fueron identificadas como identificadores, residuos de procesos anteriores o columnas con alta cardinalidad sin aporte predictivo, y por lo tanto fueron eliminadas durante el proceso de limpieza de datos.

###  Observaciones adicionales
- No se detectaron valores nulos en las columnas relevantes del dataset.
- La variable `OBJ` presenta un balance de clases que ser谩 evaluado posteriormente para determinar la necesidad de t茅cnicas de balanceo.
- El an谩lisis se enfocar谩 principalmente en el grupo de variables absolutas (`V1` a `V30`), descartando el grupo de variables relativas para evitar p茅rdida


## 3. Limpieza y Preprocesamiento de Datos

El tratamiento de limpieza de datos realizado fue el siguiente proceso:

#### 3.1. Eliminaci贸n de columnas irrelevantes o identificadores
Se eliminaron las columnas `ALEAT`, `ID` y `VT` porque presentaban valores 煤nicos o casi 煤nicos por fila, actuando como identificadores t茅cnicos sin valor predictivo para el modelo.  
Esto contribuye a reducir el riesgo de sobreajuste y eliminar ruido en los datos.

#### 3.2. Eliminaci贸n de columnas residuales con alta cardinalidad y valores residuales num茅ricos
Las columnas `V31_P` y `V31_P.1` fueron eliminadas al presentar alta cantidad de valores 煤nicos, predominancia de ceros y valores extremadamente peque帽os.  
Estas caracter铆sticas son indicativas de residuos o transformaciones previas sin relevancia para el modelo.

#### 3.3. Verificaci贸n y confirmaci贸n de ausencia de valores nulos
Se comprob贸 que todas las columnas restantes tienen un 0% de valores nulos, por lo que no fue necesario aplicar t茅cnicas de imputaci贸n ni eliminar registros.  
Esto asegura la consistencia del dataset y evita errores durante el entrenamiento de los modelos.

> **Nota:** Todas las columnas mencionadas en los puntos anteriores fueron eliminadas antes de iniciar el proceso de modelado.

## 4. An谩lisis Preliminar de los Datos
### 4.1. Distribuci贸n de la Variable Objetivo (`OBJ`)

Se utiliz贸 `sns.countplot` para visualizar la cantidad de registros pertenecientes a cada clase de la variable `OBJ`.

![alt text](recursos/img-1.png)

**Resultado observado:**

- Aproximadamente **27%** de registros corresponden a la clase **'SI'** (valor = 1).
- Aproximadamente **73%** de registros corresponden a la clase **'NO'** (valor = 0).

**Interpretaci贸n:**  
El dataset presenta un claro desbalance de clases, lo cual puede afectar el rendimiento de los modelos de clasificaci贸n.  
Ser谩 necesario considerar t茅cnicas como el ajuste de pesos o el uso de balanceo de clases (por ejemplo, SMOTE).

---

### 4.2. Matriz de Correlaci贸n entre Variables Absolutas (`V1` a `V30`)

Se utiliz贸 `sns.heatmap(X.corr())` para analizar la relaci贸n lineal entre las variables independientes.

![alt text](recursos/imagen-2.png)

**Observaciones:**

- La diagonal muestra correlaci贸n perfecta (valor = 1) consigo misma, como es esperable.
- El resto de las correlaciones entre pares de variables presenta valores relativamente bajos, con algunos bloques donde existe ligera correlaci贸n positiva o negativa.

**Interpretaci贸n:**  
No se detectan problemas graves de multicolinealidad.  
Las variables relativas no son redundantes entre s铆, por lo que todas podr铆an aportar informaci贸n al modelo.

## 5. Divisi贸n de Datos y Balanceo de Clases con SMOTE

### 5.1. Motivo del Balanceo

Durante el an谩lisis preliminar se observ贸 un desbalance entre clases en `OBJ` (~27% SI vs ~73% NO).  
Este desbalance puede hacer que los modelos de clasificaci贸n aprendan a predecir mayoritariamente la clase mayoritaria, afectando especialmente m茅tricas como **F1-score** o **Recall** de la clase minoritaria.

SMOTE (Synthetic Minority Over-sampling Technique) genera nuevas muestras sint茅ticas de la clase minoritaria, creando puntos intermedios entre registros existentes, sin simplemente duplicar datos.

![alt text](recursos/imagen-3.png)

### 5.2. Resultado Observado

Despu茅s de aplicar SMOTE, la distribuci贸n de clases qued贸 perfectamente balanceada:

- **5000 registros para 'SI'.**
- **5000 registros para 'NO'.**

>  **Nota:** Este paso permite que el modelo entrene de manera equilibrada, sin sesgo hacia una clase, mejorando la capacidad de generalizaci贸n.

## 4. Modelos de Clasificaci贸n Implementados

- **Modelos evaluados:**  
  - RandomForestClassifier  
  - LogisticRegression  

- **Configuraci贸n inicial y preprocesamiento:**  
  - Divisi贸n 70% train / 30% test con `stratify=y`.  
  - Estandarizaci贸n solo para Logistic Regression.  
  - Evaluaci贸n con `cross_val_score` utilizando `scoring='f1'` para comparar modelos.

## 5. Optimizaci贸n de Hiperpar谩metros

- **T茅cnica utilizada:** GridSearchCV con Cross Validation (3 folds).  
- **Espacio de b煤squeda:**  
  - Para RandomForest:  
    - `n_estimators`: [100, 200, 500]  
    - `max_depth`: [None, 10, 20]  
    - `min_samples_leaf`: [1, 2, 4]  

  - Para Logistic Regression:  
    - `C`: [0.1, 1, 10]  
    - `penalty`: ['l2']  

## 6. Resultados

- **Indicadores evaluados:** F1-score, AUC, matriz de confusi贸n, curva ROC.  
- **Comparativa entre modelos:**  
  Se observ贸 que el modelo `RandomForestClassifier` con `n_estimators=200`, `max_depth=20`, y `min_samples_leaf=2` present贸 el mejor balance entre F1-score y AUC.

## 7. Justificaci贸n del Modelo Seleccionado

- **Modelo final elegido:** RandomForestClassifier  
- **Motivo de selecci贸n:**  
  - Mejor desempe帽o global en t茅rminos de F1-score promedio y estabilidad entre folds.  
  - Menor sensibilidad a outliers y escalado de datos respecto a Logistic Regression.  
  - Configuraci贸n 贸ptima seleccionada basada en el resultado del Grid Search.

## 8. Conclusi贸n

- El modelo seleccionado cumple con el objetivo de clasificaci贸n binaria sobre la variable `OBJ` utilizando variables relativas.  
- El flujo completo de limpieza, modelado, validaci贸n y selecci贸n de hiperpar谩metros fue documentado en el notebook adjunto, junto con visualizaciones de m茅tricas clave.

---

