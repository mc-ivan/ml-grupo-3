
---

![alt text](recursos/machine-learning.jpg)

# Proyecto de Clasificaci贸n Supervisada - Clasificaci贸n Binaria

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mc-ivan/ml-grupo-3/blob/main/notebook/proyecto_final_grupo_3_ajustado_var_originales.ipynb)

## Datos Generales:
**Maestria en Ciencia de Datos e Inteligencia Artifivial V1-E2**

**M贸dulo:** Machine Learning and Deep learning

# GRUPO 3
### Integrantes:
- Karen Torrico 
- Karem Huacota 
- Yesika Luna
- Elvis Miranda
- Ivan Mamani 

**Fecha de Presentaci贸n:** 18/07/2025

---

## 1. Descripci贸n del Problema

En el presente trabajo se aborda un problema de clasificaci贸n supervisada utilizando un conjunto de datos cuyo objetivo es predecir la variable `OBJ`, de naturaleza binaria. Esta variable representa dos posibles categor铆as, configurando un problema de clasificaci贸n binaria.

- **Variable objetivo (target):**  
  `OBJ` (variable binaria). La variable `OBJ` adopta valores 0 o 1, indicando la clase o categor铆a correspondiente a cada observaci贸n.

- **Variables independientes:**  
  El conjunto de datos cuenta con dos grupos diferenciados de variables predictoras:

  **a) Variables Absolutas:**  
  `V1`, `V2`, `V3`, ..., `V30`. Corresponden a valores num茅ricos en escala absoluta, relacionados con caracter铆sticas o mediciones directas de cada observaci贸n.

  **b) Variables Relativas:**  
  `V1_P`, `V2_P`, `V3_P`, ..., `V30_P`. Representan los valores absolutos normalizados respecto al total de las 30 variables originales, expresando proporciones o porcentajes dentro de cada registro.

- **Decisi贸n de trabajo:**  
  Tras un an谩lisis preliminar, se decidi贸 trabajar con las **variables originales en valores absolutos** (`V1` a `V30`) para la construcci贸n de los modelos.  
  La decisi贸n se basa en que las variables relativas (`V1_P` a `V30_P`) reflejan 煤nicamente proporciones internas, que pueden resultar insuficientes para capturar relaciones m谩s complejas o magnitudes reales entre observaciones.  
  Al emplear las variables absolutas se conserva la informaci贸n completa de las mediciones, permitiendo a los modelos explorar tanto la relaci贸n entre valores individuales como su escala.

## 2. An谩lisis Exploratorio del Dataset

El dataset `GRUPO 3_1.zip` utilizado en este laboratorio est谩 compuesto por un total de **10,000 registros (filas)** y **66 columnas** en su versi贸n original.

### 2.1. Estructura inicial del Dataset
- **Cantidad de filas (observaciones):** 10,000  
- **Cantidad de columnas (variables):** 66  

### 2.2. Composici贸n de las columnas
- **1 variable objetivo:** `OBJ` (variable binaria: clasificaci贸n entre dos categor铆as)

- **30 variables independientes en valores absolutos:**  
  - `V1`, `V2`, `V3`, ..., `V30`  

- **30 variables independientes en valores relativos (proporciones):**  
  - `V1_P`, `V2_P`, `V3_P`, ..., `V30_P`  

- **5 columnas t茅cnicas o auxiliares inicialmente presentes:**  
  - `ALEAT`, `ID`, `VT`, `V31_P`, `V31_P.1`  
  - Estas columnas fueron identificadas como identificadores, residuos de procesos anteriores o columnas con alta cardinalidad sin aporte predictivo, y por lo tanto fueron eliminadas durante el proceso de limpieza de datos.

###  Observaciones adicionales
- No se detectaron valores nulos en las columnas relevantes del dataset.
- La variable `OBJ` presenta un balance de clases que ser谩 evaluado posteriormente para determinar la necesidad de t茅cnicas de balanceo.
- El an谩lisis se enfocar谩 principalmente en el grupo de variables absolutas (`V1` a `V30`), descartando el grupo de variables relativas para evitar p茅rdida


## 3. Limpieza y Preprocesamiento de Datos

El tratamiento de limpieza de datos realizado fue el siguiente proceso:

#### 3.1. Eliminaci贸n de columnas irrelevantes o identificadores
Se eliminaron las columnas `ALEAT`, `ID` y `VT` porque presentaban valores 煤nicos o casi 煤nicos por fila, actuando como identificadores t茅cnicos sin valor predictivo para el modelo.  
Esto contribuye a reducir el riesgo de sobreajuste y eliminar ruido en los datos.

#### 3.2. Eliminaci贸n de columnas residuales con alta cardinalidad y valores residuales num茅ricos
Las columnas `V31_P` y `V31_P.1` fueron eliminadas al presentar alta cantidad de valores 煤nicos, predominancia de ceros y valores extremadamente peque帽os.  
Estas caracter铆sticas son indicativas de residuos o transformaciones previas sin relevancia para el modelo.

#### 3.3. Verificaci贸n y confirmaci贸n de ausencia de valores nulos
Se comprob贸 que todas las columnas restantes tienen un 0% de valores nulos, por lo que no fue necesario aplicar t茅cnicas de imputaci贸n ni eliminar registros.  
Esto asegura la consistencia del dataset y evita errores durante el entrenamiento de los modelos.

> **Nota:** Todas las columnas mencionadas en los puntos anteriores fueron eliminadas antes de iniciar el proceso de modelado.

## 4. An谩lisis Preliminar de los Datos
### 4.1. Distribuci贸n de la Variable Objetivo (`OBJ`)

Se utiliz贸 `sns.countplot` para visualizar la cantidad de registros pertenecientes a cada clase de la variable `OBJ`.

![alt text](recursos/img-1.png)

**Resultado observado:**

- Aproximadamente **27%** de registros corresponden a la clase **'SI'** (valor = 1).
- Aproximadamente **73%** de registros corresponden a la clase **'NO'** (valor = 0).

**Interpretaci贸n:**  
El dataset presenta un claro desbalance de clases, lo cual puede afectar el rendimiento de los modelos de clasificaci贸n.  
Ser谩 necesario considerar t茅cnicas como el ajuste de pesos o el uso de balanceo de clases (por ejemplo, SMOTE).

---

### 4.2. Matriz de Correlaci贸n entre Variables Absolutas (`V1` a `V30`)

Se utiliz贸 `sns.heatmap(X.corr())` para analizar la relaci贸n lineal entre las variables independientes.

![alt text](recursos/imagen-2.png)

**Observaciones:**

- La diagonal muestra correlaci贸n perfecta (valor = 1) consigo misma, como es esperable.
- El resto de las correlaciones entre pares de variables presenta valores relativamente bajos, con algunos bloques donde existe ligera correlaci贸n positiva o negativa.

**Interpretaci贸n:**  
No se detectan problemas graves de multicolinealidad.  
Las variables relativas no son redundantes entre s铆, por lo que todas podr铆an aportar informaci贸n al modelo.

## 5. Divisi贸n de Datos y Balanceo de Clases con SMOTE

### 5.1. Motivo del Balanceo

Durante el an谩lisis preliminar se observ贸 un desbalance entre clases en `OBJ` (~27% SI vs ~73% NO).  
Este desbalance puede hacer que los modelos de clasificaci贸n aprendan a predecir mayoritariamente la clase mayoritaria, afectando especialmente m茅tricas como **F1-score** o **Recall** de la clase minoritaria.

SMOTE (Synthetic Minority Over-sampling Technique) genera nuevas muestras sint茅ticas de la clase minoritaria, creando puntos intermedios entre registros existentes, sin simplemente duplicar datos.

![alt text](recursos/imagen-3.png)

### 5.2. Resultado Observado

Despu茅s de aplicar SMOTE, la distribuci贸n de clases qued贸 perfectamente balanceada:

- **5000 registros para 'SI'.**
- **5000 registros para 'NO'.**

>  **Nota:** Este paso permite que el modelo entrene de manera equilibrada, sin sesgo hacia una clase, mejorando la capacidad de generalizaci贸n.

## 6. Modelos de Clasificaci贸n Implementados

Con el objetivo de resolver el problema de clasificaci贸n binaria planteado, se implementaron y evaluaron los siguientes modelos de aprendizaje supervisado:

- **Regresi贸n Log铆stica (Logistic Regression):**  
  Modelo lineal de referencia, utilizado por su simplicidad y capacidad interpretativa. Se ajust贸 el hiperpar谩metro de regularizaci贸n `C` y se aplic贸 balanceo de clases mediante `class_weight='balanced'`.

- **Bosque Aleatorio (Random Forest Classifier):**  
  Algoritmo de ensamble basado en 谩rboles de decisi贸n. Se exploraron diferentes cantidades de 谩rboles (`n_estimators`), profundidad m谩xima (`max_depth`) y restricciones para el crecimiento de los 谩rboles (`min_samples_split`, `min_samples_leaf`). Tambi茅n se incorpor贸 balanceo de clases.

- **M谩quinas de Vectores de Soporte con Kernel RBF (SVM RBF):**  
  Modelo no lineal que permite capturar relaciones complejas entre las variables. Se ajustaron los par谩metros `C` y `gamma`. Se activ贸 el c谩lculo de probabilidades y se aplic贸 balanceo de clases.

- **XGBoost Classifier:**  
  Algoritmo de Gradient Boosting optimizado para clasificaci贸n, reconocido por su alto rendimiento en competencias de machine learning. Se ajustaron `n_estimators`, `max_depth` y `scale_pos_weight` para tratar el desbalance de clases.

 **Observaciones:**

Se eligieron estos cuatro modelos por cubrir diferentes enfoques de clasificaci贸n:

- Modelos lineales y no lineales.
- Modelos con capacidad de manejar desbalance de clases mediante par谩metros espec铆ficos.
- Algoritmos basados en 谩rboles y m茅todos de boosting, que tienden a ofrecer alto rendimiento en problemas reales.

Cada modelo fue ajustado mediante `GridSearchCV` para optimizar su configuraci贸n de hiperpar谩metros, empleando validaci贸n cruzada estratificada con la m茅trica `F1-score` como referencia principal.

## 7. Optimizaci贸n de Hiperpar谩metros

La optimizaci贸n de hiperpar谩metros constituye un paso esencial en la construcci贸n de modelos de clasificaci贸n robustos y con buen rendimiento predictivo. Los hiperpar谩metros son configuraciones externas a los modelos que controlan aspectos como la complejidad, la regularizaci贸n o el n煤mero de 谩rboles, y no se aprenden directamente a partir de los datos. Elegir adecuadamente estos valores puede marcar una diferencia sustancial en la capacidad del modelo para generalizar correctamente a nuevos datos.

### 7.1. 驴Por qu茅 es necesaria la optimizaci贸n de hiperpar谩metros?

Durante el an谩lisis exploratorio se identific贸 un marcado desbalance en la variable objetivo (`clase 1`: positiva, `clase 0`: negativa). En este tipo de contextos, los modelos tienden a sesgarse hacia la clase mayoritaria, lo que puede generar m茅tricas infladas (por ejemplo, una alta exactitud con bajo poder predictivo real). Por ello, no solo se procedi贸 a balancear el conjunto de entrenamiento, sino tambi茅n a realizar una b煤squeda cuidadosa de combinaciones de hiperpar谩metros que maximicen la capacidad del modelo para distinguir ambas clases. Para esto se emple贸 como m茅trica principal el `F1-score`, que balancea precisi贸n y recall, y es m谩s apropiado que la simple exactitud en contextos desbalanceados.


### 7.2. Metodolog铆a aplicada

#### 7.2.1. Balanceo con SMOTE 
   Se utiliz贸 la t茅cnica SMOTE (Synthetic Minority Over-sampling Technique) para aumentar de forma sint茅tica la clase minoritaria en el conjunto de entrenamiento. Esto permiti贸 entrenar los modelos con una distribuci贸n m谩s equitativa de clases, aumentando su capacidad para detectar correctamente instancias positivas.

### 7.2.2. Selecci贸n de Modelos y Hiperpar谩metros  
   Se consideraron cuatro algoritmos de clasificaci贸n representativos:

   - Regresi贸n Log铆stica
   - Random Forest
   - M谩quinas de Vectores de Soporte con kernel RBF (SVM-RBF)
   - XGBoost

   Para cada uno de ellos se defini贸 una cuadr铆cula de hiperpar谩metros relevante. Por ejemplo:

   - En Random Forest se probaron distintas profundidades de 谩rbol, n煤mero de 谩rboles y tama帽o m铆nimo de hojas.
   - En SVM se evaluaron distintos valores del par谩metro de regularizaci贸n `C` y del kernel `gamma`.
   - En XGBoost se ajust贸 el par谩metro scale_pos_weight para enfrentar el desbalance de clases.

### 7.2.3. Validaci贸n Cruzada y GridSearchCV  
   Se aplic贸 una validaci贸n cruzada estratificada de 5 pliegues mediante GridSearchCV, lo que permiti贸 evaluar el rendimiento promedio de cada combinaci贸n de hiperpar谩metros. Este enfoque asegura una estimaci贸n m谩s robusta del desempe帽o y reduce el riesgo de sobreajuste a una 煤nica partici贸n de los datos.

### 7.2.4. Evaluaci贸n y Selecci贸n 
   Para cada modelo se almacenaron:

   - Los mejores hiperpar谩metros encontrados
   - El modelo ya entrenado con dichos par谩metros
   - El mejor F1-score promedio obtenido durante la validaci贸n cruzada

   Posteriormente, los modelos 贸ptimos fueron evaluados sobre un conjunto de prueba independiente, donde se analizaron m茅tricas como precisi贸n, recall, F1-score, AUC, as铆 como matrices de confusi贸n y curvas ROC.


 **Observaciones:**

Este proceso de optimizaci贸n permiti贸 comparar de forma justa el rendimiento de distintos algoritmos en condiciones balanceadas y bajo criterios objetivos. Al ajustar adecuadamente los hiperpar谩metros y emplear t茅cnicas espec铆ficas para lidiar con el desbalance, se logr贸 mejorar significativamente la capacidad de los modelos para identificar la clase minoritaria, lo cual es clave en el contexto del problema analizado.

## 8. Interpretaci贸n de las M茅tricas y Resultados por Modelo

A continuaci贸n, se presentan los resultados obtenidos tras la evaluaci贸n final de los modelos optimizados mediante b煤squeda de hiperpar谩metros. El an谩lisis se basa en m茅tricas como precisi贸n, recall, F1-score, matriz de confusi贸n y AUC (rea Bajo la Curva ROC), considerando el importante desbalance de clases del problema.


### 8.1. Modelo Logistic Regression
![alt text](recursos/imagen-12.png)

**Mejores hiperpar谩metros:** `C = 10`

**M茅tricas de desempe帽o**

| Clase | Precisi贸n | Recall | F1-Score | Soporte |
|-------|-----------|--------|----------|---------|
| 0 (NO) | 0.77 | 0.55 | 0.64 | 2225 |
| 1 (SI) | 0.29 | 0.52 | 0.37 | 775 |

- Exactitud (Accuracy): 0.54  
- AUC: 0.563  
- Macro promedio F1-score: 0.51  
- Weighted promedio F1-score: 0.57

**Interpretaci贸n gr谩fica**

**Matriz de Confusi贸n**

![alt text](recursos/imagen-4.png)
  - La clase mayoritaria (NO) se predice con precisi贸n aceptable, pero presenta una alta tasa de falsos positivos.
  - La clase minoritaria (SI) es parcialmente identificada (recall 0.52), pero con una baja precisi贸n (0.29).

**Curva ROC**

![alt text](recursos/imagen-5.png)

  - El valor de AUC (0.56) sugiere una capacidad de discriminaci贸n apenas superior al azar.


### 8.2. Modelo Random Forest

![alt text](recursos/imagen-13.png)

**Mejores hiperpar谩metros**  
`max_depth = 5`, `min_samples_leaf = 1`, `min_samples_split = 10`, `n_estimators = 50`

**M茅tricas de desempe帽o**

| Clase | Precisi贸n | Recall | F1-Score | Soporte |
|-------|-----------|--------|----------|---------|
| 0 (NO) | 0.81 | 0.61 | 0.70 | 2225 |
| 1 (SI) | 0.34 | 0.58 | 0.43 | 775 |

- Exactitud (Accuracy): 0.60  
- AUC: 0.622  
- Macro promedio F1-score: 0.56  
- Weighted promedio F1-score: 0.63

**Interpretaci贸n gr谩fica**

**Matriz de Confusi贸n**

![alt text](recursos/imagen-6.png)

  - Mejora significativa en la identificaci贸n de ambas clases respecto al modelo log铆stico.
  - El modelo ofrece un balance razonable entre precisi贸n y recall, destacando en recall para la clase SI (0.58).

**Curva ROC**

![alt text](recursos/imagen-7.png)

  - Con un AUC de 0.62, Random Forest es el modelo con mejor capacidad discriminativa entre clases hasta el momento.


### 8.3. Modelo SVM con kernel RBF

![alt text](recursos/imagen-14.png)

**Mejores hiperpar谩metros**  
`C = 0.1`, `gamma = 0.001`

**M茅tricas de desempe帽o**

| Clase | Precisi贸n | Recall | F1-Score | Soporte |
|-------|-----------|--------|----------|---------|
| 0 (NO) | 0.84 | 0.07 | 0.13 | 2225 |
| 1 (SI) | 0.26 | 0.96 | 0.42 | 775 |

- Exactitud (Accuracy): 0.30  
- AUC: 0.524  
- Macro promedio F1-score: 0.27  
- Weighted promedio F1-score: 0.20

**Interpretaci贸n gr谩fica**

**Matriz de Confusi贸n**

![alt text](recursos/imagen-8.png)

  - El modelo clasifica la mayor铆a de los casos como clase 'SI', lo que resulta en un recall muy alto (0.96) pero con una precisi贸n muy baja (0.26), generando muchos falsos positivos.
  - Para la clase 'NO', el modelo falla casi completamente (recall 0.07).

**Curva ROC**

![alt text](recursos/imagen-9.png)

  - AUC de 0.52, lo cual refleja un desempe帽o casi aleatorio en la separaci贸n de clases.


### 8.4. Modelo XGBoost

![alt text](recursos/imagen-15.png)

**Mejores hiperpar谩metros**  
`max_depth = 3`, `n_estimators = 100`, `scale_pos_weight = 5`

**M茅tricas de desempe帽o**

| Clase | Precisi贸n | Recall | F1-Score | Soporte |
|-------|-----------|--------|----------|---------|
| 0 (NO) | 0.79 | 0.34 | 0.48 | 2225 |
| 1 (SI) | 0.28 | 0.74 | 0.41 | 775 |

- Exactitud (Accuracy): 0.45  
- AUC: 0.596  
- Macro promedio F1-score: 0.44  
- Weighted promedio F1-score: 0.46

**Interpretaci贸n gr谩fica:**

**Matriz de Confusi贸n**

![alt text](recursos/imagen-10.png)

  - El modelo muestra una mejora en el recall de la clase minoritaria (0.74), pero la precisi贸n sigue siendo baja (0.28), provocando muchos falsos positivos.
  - El rendimiento en la clase mayoritaria se ve comprometido con una ca铆da del recall a 0.34.

**Curva ROC**

![alt text](recursos/imagen-11.png)

  - Un AUC de 0.60 sugiere que el modelo logra una discriminaci贸n razonable, aunque no 贸ptima.


 **Observaciones:**

- El modelo de Random Forest se destaca por ofrecer el mejor equilibrio entre precisi贸n y recall para ambas clases, y el mayor AUC.
- SVM_RBF logra un alto recall en la clase minoritaria (SI), pero a costa de una alta cantidad de falsos positivos, lo cual lo vuelve poco viable en escenarios pr谩cticos.
- Logistic Regression y XGBoost ofrecen desempe帽os limitados, siendo este 煤ltimo m谩s competitivo en recall pero con problemas de precisi贸n.

### Determinaci贸n de Mejor Modelo

| Modelo               | Accuracy | Precision (Clase 1) | Recall (Clase 1) | F1-Score (Clase 1) | AUC   |
|----------------------|----------|----------------------|-------------------|---------------------|-------|
| Logistic Regression  | 0.54     | 0.29                 | 0.52              | 0.37                | 0.56  |
| **Random Forest**        | **0.60**     | **0.34**                 | **0.58**              | **0.43**                | **0.62**  |
| SVM (RBF)            | 0.30     | 0.26                 | 0.96              | 0.42                | 0.52  |
| XGBoost              | 0.45     | 0.28                 | 0.74              | 0.41                | 0.60  |

RandomForest parece ser el modelo m谩s equilibrado, indicando que siempre se puede reajustar para obtener mejores resultados.


## 9. Resultados

La fase final del an谩lisis consisti贸 en evaluar el rendimiento de distintos modelos de clasificaci贸n aplicados al problema planteado, considerando un conjunto de m茅tricas clave: precisi贸n, recall, F1-score y el 谩rea bajo la curva ROC (AUC). El objetivo fue determinar qu茅 modelo ofrec铆a un mejor balance entre la identificaci贸n correcta de ambas clases, en particular de la clase minoritaria ('SI'), que reviste mayor inter茅s desde el punto de vista anal铆tico.

Los modelos evaluados fueron: Regresi贸n Log铆stica, Random Forest, M谩quina de Vectores de Soporte con kernel RBF (SVM_RBF) y XGBoost. Todos los modelos fueron previamente ajustados mediante b煤squeda de hiperpar谩metros con validaci贸n cruzada estratificada, empleando balanceo de clases mediante SMOTE y/o el par谩metro class_weight.

A continuaci贸n se detallan los resultados m谩s relevantes:

- La Regresi贸n Log铆stica present贸 un rendimiento modesto con un AUC de 0.563. Aunque su precisi贸n para la clase 'NO' fue aceptable (0.77), el modelo tuvo dificultades para identificar correctamente la clase 'SI' (F1-score de 0.37).

- El modelo de Random Forest obtuvo el mejor rendimiento general. Logr贸 el F1-score m谩s alto para ambas clases (0.70 para 'NO' y 0.43 para 'SI') y el AUC m谩s elevado (0.622), lo que refleja una capacidad m谩s balanceada para clasificar ambas categor铆as. Este modelo fue el que mejor comprometi贸 entre sensibilidad y precisi贸n para la clase minoritaria.

- El modelo SVM con kernel RBF mostr贸 un comportamiento desequilibrado. Si bien alcanz贸 un recall muy alto para la clase 'SI' (0.96), su precisi贸n fue baja (0.26), resultando en un F1-score de solo 0.42. Adem谩s, el desempe帽o sobre la clase 'NO' fue deficiente (F1-score de 0.13), y el AUC total fue de 0.524.

- El modelo XGBoost ofreci贸 un rendimiento intermedio. Su capacidad para detectar la clase 'SI' fue razonable (recall de 0.74), aunque con baja precisi贸n (0.28), resultando en un F1-score de 0.41 y un AUC de 0.596. Fue mejor que SVM y Log铆stica, pero inferior a Random Forest.

#### Comparaci贸n General de Desempe帽o

| Modelo              | F1 (NO) | F1 (SI) | AUC   |
|---------------------|---------|---------|-------|
| Logistic Regression | 0.64    | 0.37    | 0.563 |
| Random Forest       | 0.70    | 0.43    | 0.622 |
| SVM (RBF)           | 0.13    | 0.42    | 0.524 |
| XGBoost             | 0.48    | 0.41    | 0.596 |

 **Observaciones:**

El modelo Random Forest emergi贸 como el m谩s robusto y equilibrado en cuanto a la clasificaci贸n de ambas clases, superando a los dem谩s modelos en F1-score combinado y AUC. A pesar de que ning煤n modelo logr贸 una clasificaci贸n completamente satisfactoria para la clase minoritaria ('SI'), Random Forest represent贸 el mejor compromiso observado entre sensibilidad y precisi贸n.

El an谩lisis demuestra que, si bien el balanceo y la optimizaci贸n de hiperpar谩metros mejoraron el rendimiento general, el problema sigue presentando un desaf铆o debido al desbalance de clases y la posible superposici贸n entre categor铆as.


## 10. Justificaci贸n del Modelo Seleccionado

Tras la evaluaci贸n comparativa de m煤ltiples algoritmos de clasificaci贸n (Logistic Regression, Random Forest, SVM con kernel RBF y XGBoost), se seleccion贸 el modelo Random Forest como el m谩s adecuado para resolver el problema de predicci贸n de clientes que realizar谩n compras en base a variables de comportamiento y segmentaci贸n.

La decisi贸n se fundamenta en los siguientes aspectos:

1.Desempe帽o balanceado entre clases:
   - El modelo Random Forest logr贸 un equilibrio razonable entre la precisi贸n (0.34) y el recall (0.58) para la clase minoritaria (clientes compradores), lo que implica una mayor capacidad para identificar correctamente a estos clientes sin incurrir en una explosi贸n de falsos positivos.
   - Esto contrasta con modelos como SVM, que priorizan el recall (0.96) a costa de una precisi贸n extremadamente baja (0.26), lo cual puede ser inviable operativamente.

2.Mejor capacidad discriminativa (AUC):
   - Con un AUC de 0.621, Random Forest presenta la mayor capacidad para distinguir entre clases comparado con Logistic Regression (0.563), XGBoost (0.596) y SVM (0.524).
   - Esta m茅trica es especialmente relevante en problemas con clases desbalanceadas, ya que permite evaluar el modelo de forma independiente del umbral de clasificaci贸n.

3.Estabilidad y robustez del modelo:
   - Random Forest, al ser un modelo basado en ensamble de 谩rboles, ofrece mayor robustez frente al ruido, overfitting y a relaciones no lineales o interacciones complejas entre variables predictoras.
   - Esta caracter铆stica es clave en entornos de marketing donde los patrones de comportamiento de los clientes no siempre siguen relaciones lineales.

4.Interpretabilidad y trazabilidad:
   - Si bien no es tan interpretable como una regresi贸n log铆stica, el modelo Random Forest permite extraer la importancia de las variables, lo que facilita insights estrat茅gicos sobre los factores que m谩s influyen en la probabilidad de compra.

5.Desempe帽o operativo (accuracy y f1-score):
   - En t茅rminos generales, Random Forest obtuvo una accuracy superior (0.60) y el mayor F1-score para la clase minoritaria (0.43), lo cual indica un buen balance entre precisi贸n y sensibilidad.

Entonces, Random Forest sobresale como una opci贸n robusta y eficiente para este problema, al ofrecer el mejor rendimiento general en m茅tricas cr铆ticas y un comportamiento razonable frente al desbalance de clases. Esto lo convierte en el modelo m谩s confiable para su implementaci贸n operativa en estrategias de targeting comercial o campa帽as de retenci贸n.


## 11. Conclusiones y Recomendaciones

### 11.1. Conclusiones

1. El proceso de modelado permiti贸 comparar de forma rigurosa diferentes algoritmos de clasificaci贸n (Logistic Regression, Random Forest, SVM y XGBoost) para predecir la probabilidad de compra de clientes a partir de un conjunto de variables demogr谩ficas y de comportamiento.

2. Se aplicaron t茅cnicas de optimizaci贸n de hiperpar谩metros (GridSearchCV) que mejoraron significativamente el rendimiento de los modelos evaluados, permitiendo encontrar configuraciones 贸ptimas para cada caso.

3. El modelo Random Forest fue seleccionado como el m谩s adecuado, destacando por:
    - Su mejor desempe帽o en m茅tricas clave como AUC (0.621) y F1-score en la clase positiva (0.43).
    - Un balance adecuado entre precisi贸n y sensibilidad frente a un conjunto de datos con desbalance de clases.
    - Su capacidad para manejar relaciones no lineales y ofrecer interpretabilidad mediante la evaluaci贸n de importancia de variables.

4. El an谩lisis gr谩fico de curvas ROC, matrices de confusi贸n y reportes de clasificaci贸n respald贸 emp铆ricamente esta elecci贸n, mostrando que otros modelos o bien priorizaban excesivamente una m茅trica a costa de otra, o no ofrec铆an mejoras sustanciales frente a Random Forest.

5. Las variables m谩s importantes identificadas por el modelo pueden orientar futuras estrategias de segmentaci贸n, recomendaci贸n de productos o ajustes en campa帽as comerciales.

### 11.2. Recomendaciones

Se recomienda explorar modelos adicionales para aportar beneficios adicionales, especialmente si se integran con t茅cnicas de ensemble o stacking.

Implementar el modelo Random Forest seleccionadoen entornos de producci贸n que pueda integrarse en sistemas de CRM o plataformas de campa帽as digitales para apoyar decisiones automatizadas de targeting.

Es importante establecer m茅tricas de seguimiento para validar el comportamiento del modelo en datos reales y detectar posibles ca铆das de rendimiento por cambios en el comportamiento del consumidor.

En s铆ntesis, el modelo Random Forest representa una herramienta valiosa para anticipar comportamientos de compra, pero su efectividad depender谩 del mantenimiento continuo, la integraci贸n con decisiones estrat茅gicas de negocio y la capacidad para adaptarse a contextos din谩micos del mercado.

## Ejecutar en Google Colab

Para explorar el notebook y reproducir los resultados, puedes abrir el proyecto directamente en Google Colab usando el siguiente bot贸n:

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mc-ivan/ml-grupo-3/blob/main/notebook/proyecto_final_grupo_3_ajustado_var_originales.ipynb)


## Licencia

Este informe y los contenidos asociados (c贸digo fuente, gr谩ficos, interpretaciones y documentaci贸n) han sido desarrollados con fines acad茅micos y/o investigativos en el marco del proyecto de an谩lisis de modelos de clasificaci贸n.

Salvo que se indique lo contrario, este trabajo se distribuye bajo la Licencia Creative Commons Atribuci贸n-NoComercial-CompartirIgual 4.0 Internacional (CC BY-NC-SA 4.0).

Para m谩s detalles sobre la licencia, consultar:

[![Licencia: CC BY-NC-SA 4.0](https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
